---
title: "sherryx_OriginalHomeworkCode_04"
author: "Sherry Xie"
date: "2025-03-10"
output: html_document
---

## Set up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#loading ggplot for the figures
library(ggplot2)
library(tidyverse)
library(dplyr)
library(curl)
```

## [1] Write a simple R function, `Z.prop.test()`, that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:

### Your function should take the following arguments: **p1** and **n1** (no default) representing the estimated proportion and sample size (i.e., based on your sample data); **p2** and **n2** (both defaulting to NULL) that contain a second sample‚Äôs proportion and sample size data in the event of a two-sample test; **p0** (no default) as the expected value for the population proportion; and **alternative** (default ‚Äútwo.sided‚Äù) and **conf.level** (default 0.95), to be used in the same way as in the function `t.test()`.

```{r}
# From this instruction, I will set up my function with p2, n2 = NULL
# conf.level = 0.95
```

### When conducting a two-sample test, it should be **p1** that is tested as being smaller or larger than **p2** when alternative=‚Äúless‚Äù or alternative=‚Äúgreater‚Äù, the same as in the use of x and y in the function `t.test()`.

[**FROM MODULE 10:**](https://fuzzyatelin.github.io/bioanth-stats/module-10/module-10.html) ***R*** has built into it a single function, `t.test()`, that lets us do all this in one line. We give it our data and the expected population mean, ùúáŒº, along with the kind of test we want to do.

```{r}
#t <- t.test(x = x, mu = mu, alternative = "greater")
#t
```

### The function should perform a one-sample Z-test using **p1**, **n1**, and **p0** if either **p2** or **n2** (or both) is NULL.

### The function should contain a check for the rules of thumb we have talked about (ùëõ‚àóùëù\>5n‚àóp\>5 and ùëõ‚àó(1‚àíùëù)\>5n‚àó(1‚àíp)\>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

```{r}
# Challenge, could not remember this rule of thumb and where we have seen this. So I just followed what is written in the instruction
```

### The function should return a list containing the members **Z** (the test statistic), **P** (the appropriate p value), and **CI** (the two-sided CI with respect to ‚Äúconf.level‚Äù around **p1** in the case of a one-sample test and around **p2-p1** in the case of a two-sample test). For all test alternatives (‚Äútwo.sided‚Äù, ‚Äúgreater‚Äù, ‚Äúless‚Äù), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}
# this is my overall function specifically mentioning p1, n1, p2, n2 AS THE NULL, p0, 2 sample alternative, and the confidence level
Z.prop.test.function <- function(p1, n1, p2 = NULL, n2 = NULL, p0, alternative = "two.sided", conf.level = 0.95) {
  
  # Rule of thumb check, literally copying and pasting from the instruction because I do not remember seeing this in the module (my fault)
  # This is also for sample 1 
  if (n1 * p1 < 5 || n1 * (1 - p1) < 5) {
   
    # this warning message shows the user who still wants to proceed that the condition is violated
     warning("Warning: Sample 1 violates (np > 5 and n(1-p) > 5).")
  }
  
    # Rule of thumb check, literally copying and pasting from the instruction because I do not remember seeing this in the module (my fault)
    #DIFFERNT FROM ABOVE: THIS IS FOR A TWO-SAMPLE TEST 
  if (!is.null(p2) && !is.null(n2)) {
    if (n2 * p2 < 5 || n2 * (1 - p2) < 5) {
     
      # this warning message shows the user who still wants to proceed that the condition is violated
       warning("Warning: Sample 2 violates (np > 5 and n(1-p) > 5).")
    } 
    
# CHALLENGE: I WANT TO SPLIT THIS CODE UP BUT DO NOT KNOW HOW TO CONTINUE MY FUNCTION
    # Two-sample test
    #CI (the two-sided CI with respect to ‚Äúconf.level‚Äù around p2-p1 in the case of a two-sample test).
    p_star <- (p1 * n1 + p2 * n2) / (n1 + n2)  # pooled proportion
    #copy and pasted from module 10
    z <- (p1 - p2) / sqrt(p_star * (1 - p_star) * (1/n1 + 1/n2))
    ci <- c((p1 - p2) - qnorm(1 - (1 - conf.level) / 2) * sqrt(p_star * (1 - p_star) * (1/n1 + 1/n2)), #this is the lower CI
         (p1 - p2) + qnorm(1 - (1 - conf.level) / 2) * sqrt(p_star * (1 - p_star) * (1/n1 + 1/n2)))  #this is the upper CI
    
  } else {
    # One-sample test
    # CI (the two-sided CI with respect to ‚Äúconf.level‚Äù around p1 in the case of a one-sample test
    z <- (p1 - p0) / sqrt(p0 * (1 - p0) / n1)
    ci <- c(p1 - qnorm(1 - (1 - conf.level) / 2) * sqrt(p1 * (1 - p1) / n1), #lower CI
            p1 + qnorm(1 - (1 - conf.level) / 2) * sqrt(p1 * (1 - p1) / n1)) #upper CI
  }
  
  # Calculate p-value
  # Challenge. Was I suppose to do this for the pvalue? or just split it up into one sample vs two sample like the z and CI above?
  if (alternative == "less") {
    p_value <- pnorm(z)
  } else if (alternative == "greater") {
    p_value <- 1 - pnorm(z)
  } else {
    p_value <- 2 * (1 - pnorm(abs(z)))
  }
  
  # Return output
  return(list(
    Z = z,
    P = p_value,
    CI = ci
  ))
}
```

### Testing my function out mostly to help myself understand what is going on because the function by itself seems very abstract

```{r}
# example set 1, one sample test
Z.prop.test.function(p1 = 0.6, n1 = 50, p0 = 0.8)

```

```{r}
# example set 2, two sample test
Z.prop.test.function(p1 = 0.3, n1 = 50, p2 = 0.7, n2 = 35, p0 = 0.5)

```

```{r}
# example set 1, one sample test
# this example shows the warning sign on how the sample violates the (np > 5 and n(1-p) > 5) rule
Z.prop.test.function(p1 = 0.1, n1 = 10, p0 = 0.8)
```

## [2] The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (`MaxLongevity_m`) measured in months from species‚Äô brain size (`Brain_Size_Species_Mean`) measured in grams. Do the following for both `longevity~brain size` and `log(longevity)~log(brain size)`:

### Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function `geom_text()`).

### Identify and interpret the point estimate of the slope (ùõΩ1Œ≤1), as well as the outcome of the test associated with the hypotheses H0: ùõΩ1Œ≤1 = 0; HA: ùõΩ1Œ≤1 ‚â† 0. Also, find a 90 percent CI for the slope (ùõΩ1Œ≤1) parameter.

### Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

### Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

### Looking at your two models, which do you think is better? Why?

[The `lm()` Function copied and used from module 12](https://fuzzyatelin.github.io/bioanth-stats/module-12/module-12.html)

```{r}
library(ggplot2)

# Load data
kamilar_cooper <- read.csv("/Users/sherryxie/CODE/Github/repos/Homework/Sherry HW 4/KamilarAndCooperData.csv")
```

```{r}
# Regression Model: Longevity ~ Brain Size
lm <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = kamilar_cooper)

summary(lm)

```

```{r}
# Regression Model: log(longevity)~log(brain size)
lm_log <- lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data = kamilar_cooper)

summary(lm_log)
```

```{r}
# Scatterplot for Regression Model: Longevity ~ Brain Size

plot_lm <- ggplot(kamilar_cooper, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  geom_text(x = 1500, y = 400, label = paste("y =", round(coef(lm1)[1], 2), "+", round(coef(lm1)[2], 4), "* x")) +
  labs(title = "Longevity vs Brain Size", x = "Brain Size (g)", y = "Longevity (months)")

# Display plot
print(plot_lm)
```

```{r}
# Scatterplot for Regression Model: log(longevity)~log(brain size)

plot_lm_log <- ggplot(kamilar_cooper, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m))) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  geom_text(x = 6, y = 6, label = paste("y =", round(coef(lm2)[1], 2), "+", round(coef(lm2)[2], 4), "* log(x)")) +
  labs(title = "Log(Longevity) vs Log(Brain Size)", x = "log(Brain Size)", y = "log(Longevity)")

# Display plot
print(plot_lm_log)
```

```{r}
# CI and PI for a brain size of 800 gm
brain_size_800 <- data.frame(Brain_Size_Species_Mean = 800)
pred1 <- predict(lm1, newdata = brain_size_800, interval = "prediction", level = 0.90)

brain_size_log_800 <- data.frame(Brain_Size_Species_Mean = log(800))
pred2 <- predict(lm2, newdata = brain_size_log_800, interval = "prediction", level = 0.90)

cat("Prediction for longevity at 800 gm brain size (Model 1):", pred1, "\n")
cat("Prediction for longevity at log(800) gm brain size (Model 2):", pred2, "\n")
```

### **Summary and Interpretation**

Interpretation:

1.  Model 2 (log-log) generally provides better fit in cases with exponential-like growth or large variance.
2.  The PI bands will reveal if 800g brain size is within the observed range; if it's extrapolating beyond the data, predictions are less trustworthy.
